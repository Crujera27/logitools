/*
.____                 .__  __                .__          
|    |    ____   ____ |__|/  |_  ____   ____ |  |   ______
|    |   /  _ \ / ___\|  \   __\/  _ \ /  _ \|  |  /  ___/
|    |__(  <_> ) /_/  >  ||  | (  <_> |  <_> )  |__\___ \ 
|_______ \____/\___  /|__||__|  \____/ \____/|____/____  >
        \/    /_____/                                  \/ 
                         
        
    Copyright (C) 2024 ngel Crujera (me@crujera.net)

    This program is free software: you can redistribute it and/or modify  
    it under the terms of the GNU Affero General Public License as published by  
    the Free Software Foundation, either version 3 of the License, or  
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,  
    but WITHOUT ANY WARRANTY; without even the implied warranty of  
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the  
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License  
    along with this program. If not, see <https://www.gnu.org/licenses/>.
    
    GitHub: https://github.com/Crujera27/
    Website: https://crujera.galnod.com

*/
/*
const { ChannelType, Message, EmbedBuilder } = require("discord.js");
const config = require("../../config.js");
const { log } = require("../../functions");
const ExtendedClient = require("../../class/ExtendedClient.js");

let executeQuery;
(async () => {
    const mysql = await import('../../../tools/mysql.mjs');
    executeQuery = mysql.default;
})();

const cooldown = new Map();

// Enhanced message tracking for AI context
const USER_MESSAGE_HISTORY = new Map(); // Store recent messages per user for AI context
const AI_CONTEXT_MESSAGES = 5; // Number of recent messages to send to AI
const AI_CONTEXT_TIME_WINDOW = 300000; // 5 minutes in milliseconds

// Add these at the top of the file
const SPAM_THRESHOLD = 5; // Messages
const SPAM_TIME_WINDOW = 5000; // 5 seconds
const MESSAGE_HISTORY = new Map(); // Store recent messages
const CAPS_THRESHOLD = 0.7; // 70% caps trigger
const MAX_MENTIONS = 3;
const URL_allowlist = ['discord.com', 'github.com']; // Add trusted domains

let filterCache = {
    patterns: [],
    allowlist: [],
    lastUpdate: 0
};

const CACHE_DURATION = 5 * 60 * 1000; // 5 minutes
/*
async function updateFilterCache() {
    if (Date.now() - filterCache.lastUpdate < CACHE_DURATION) {
        return filterCache;
    }

    const [patterns] = await executeQuery(
        'SELECT pattern, type, severity FROM filter_patterns WHERE is_active = TRUE'
    );
    const [allowlist] = await executeQuery(
        'SELECT domain FROM filter_allowlist WHERE is_active = TRUE'
    );

    filterCache = {
        patterns: patterns,
        allowlist: allowlist.map(w => w.domain),
        lastUpdate: Date.now()
    };

    return filterCache;
}
*/

function isSpam(message) {
    const authorHistory = MESSAGE_HISTORY.get(message.author.id) || [];
    const now = Date.now();
    const recentMessages = authorHistory.filter(msg => now - msg.timestamp < SPAM_TIME_WINDOW);
    
    // Update history
    recentMessages.push({ content: message.content, timestamp: now });
    MESSAGE_HISTORY.set(message.author.id, recentMessages);
    
    return recentMessages.length >= SPAM_THRESHOLD;
}

function hasExcessiveCaps(content) {
    if (content.length < 8) return false;
    const upperCount = content.replace(/[^A-Z]/g, '').length;
    return upperCount / content.length > CAPS_THRESHOLD;
}

function hasExcessiveMentions(message) {
    return message.mentions.users.size > MAX_MENTIONS || 
           message.mentions.roles.size > MAX_MENTIONS;
}

function containsUnsafeUrl(content) {
    const urlRegex = /(https?:\/\/[^\s]+)/g;
    const urls = content.match(urlRegex) || [];
    return urls.some(url => !URL_allowlist.some(safe => url.includes(safe)));
}

async function checkViolations(content, message) {
    const filters = await updateFilterCache();
    let violation = null;

    // Check each pattern from database
    for (const filter of filters.patterns) {
        let matches = false;
        
        switch(filter.type) {
            case 'regex':
                matches = new RegExp(filter.pattern, 'i').test(content);
                break;
            case 'phrase':
                matches = content.includes(filter.pattern.toLowerCase());
                break;
            case 'domain':
                matches = content.includes(filter.pattern);
                break;
        }

        if (matches) {
            return {
                type: filter.type,
                severity: filter.severity
            };
        }
    }

    // Check spam/caps/mentions
    if (isSpam(message)) {
        return { type: 'spam', severity: 'middle' };
    }
    if (hasExcessiveCaps(content)) {
        return { type: 'caps', severity: 'mild' };
    }
    if (hasExcessiveMentions(message)) {
        return { type: 'mentions', severity: 'middle' };
    }
    
    // URL check using allowlist from DB
    if (containsUnsafeUrl(content, filters.allowlist)) {
        return { type: 'url', severity: 'middle' };
    }

    return null;
}

// Enhanced function to collect user message context for AI
function updateUserMessageHistory(message) {
    const userId = message.author.id;
    const now = Date.now();
    
    if (!USER_MESSAGE_HISTORY.has(userId)) {
        USER_MESSAGE_HISTORY.set(userId, []);
    }
    
    const userHistory = USER_MESSAGE_HISTORY.get(userId);
    
    // Add current message
    userHistory.push({
        content: message.content,
        timestamp: now,
        channelId: message.channel.id,
        channelName: message.channel.name
    });
    
    // Remove messages older than time window and keep only recent messages
    const filteredHistory = userHistory
        .filter(msg => now - msg.timestamp < AI_CONTEXT_TIME_WINDOW)
        .slice(-AI_CONTEXT_MESSAGES);
    
    USER_MESSAGE_HISTORY.set(userId, filteredHistory);
    
    return filteredHistory;
}

// Function to prepare context for AI analysis
function prepareAIContext(userHistory, currentMessage) {
    if (userHistory.length <= 1) {
        return currentMessage.content;
    }
    
    let context = "Contexto de mensajes recientes del usuario:\n\n";
    
    userHistory.forEach((msg, index) => {
        const isCurrentMessage = index === userHistory.length - 1;
        const prefix = isCurrentMessage ? "[MENSAJE ACTUAL]" : `[Mensaje ${index + 1}]`;
        context += `${prefix} en #${msg.channelName}: ${msg.content}\n`;
    });
    
    return context;
}

// AI Moderation function using Llama Guard 3
async function performAIModerationCheck(message) {
    try {
        const userHistory = updateUserMessageHistory(message);
        const contextualMessage = prepareAIContext(userHistory, message);
        
        // Import the Ollama module dynamically
        const { default: checkmsg } = await import('../../../tools/ollama.mjs');
        
        // Send message to Llama Guard 3 for analysis
        const aiResponse = await checkmsg(contextualMessage);
        
        if (!aiResponse || !aiResponse.message) {
            log('AI moderation response was empty or malformed', 'warn');
            return null;
        }
        
        const decision = aiResponse.message.content.trim().toLowerCase();
        let punishment = null;
        let category = null;
        
        // Parse Llama Guard 3 response
        if (decision.startsWith('unsafe')) {
            // Extract category (e.g., "unsafe\nS2" -> "S2")
            const lines = aiResponse.message.content.trim().split('\n');
            category = lines.length > 1 ? lines[1] : 'unknown';
            
            // Map Llama Guard categories to our punishment system
            punishment = mapGuardCategoryToPunishment(category, contextualMessage);
        } else if (decision === 'safe') {
            punishment = null; // No action needed
        } else {
            // Fallback for custom responses from our automod prompt
            switch (decision) {
                case 'warn_mild':
                    punishment = { type: 'warn_mild', reason: 'Contenido detectado como inapropiado por IA (leve)' };
                    break;
                case 'warn_middle':
                    punishment = { type: 'warn_middle', reason: 'Contenido detectado como inapropiado por IA (medio)' };
                    break;
                case 'warn_severe':
                    punishment = { type: 'warn_severe', reason: 'Contenido detectado como inapropiado por IA (grave)' };
                    break;
                case 'ban':
                    punishment = { type: 'ban', reason: 'Contenido detectado como extremadamente inapropiado por IA' };
                    break;
                case 'none':
                default:
                    punishment = null;
                    break;
            }
        }
        
        // Log AI decision for monitoring and improvement
        await logAIDecision(message, contextualMessage, decision, category, punishment);
        
        return punishment;
    } catch (error) {
        log(`Error in AI moderation: ${error.message}`, 'err');
        return null;
    }
}

// Log AI moderation decisions for analysis and monitoring
async function logAIDecision(message, contextualMessage, decision, category, punishment) {
    try {
        const contextHistory = USER_MESSAGE_HISTORY.get(message.author.id) || [];
        
        const logData = {
            user_id: message.author.id,
            message_content: contextualMessage,
            ai_decision: decision,
            ai_category: category,
            punishment_applied: punishment ? punishment.type : null,
            context_messages: JSON.stringify(contextHistory)
        };
        
        await executeQuery(`
            INSERT INTO ai_moderation_logs 
            (user_id, message_content, ai_decision, ai_category, punishment_applied, context_messages)
            VALUES (?, ?, ?, ?, ?, ?)
        `, [
            logData.user_id,
            logData.message_content,
            logData.ai_decision,
            logData.ai_category,
            logData.punishment_applied,
            logData.context_messages
        ]);
        
        log(`AI decision logged for user ${message.author.username}: ${decision}`, 'info');
    } catch (error) {
        log(`Failed to log AI decision: ${error.message}`, 'err');
    }
}

// Map Llama Guard 3 safety categories to punishment levels
function mapGuardCategoryToPunishment(category, content) {
    const categoryMap = {
        'S1': { type: 'ban', reason: 'Cr铆menes violentos detectados por IA' }, // Violent Crimes
        'S2': { type: 'warn_severe', reason: 'Cr铆menes no violentos detectados por IA' }, // Non-Violent Crimes
        'S3': { type: 'ban', reason: 'Contenido sexual inapropiado detectado por IA' }, // Sex-Related Crimes
        'S4': { type: 'ban', reason: 'Explotaci贸n infantil detectada por IA' }, // Child Sexual Exploitation
        'S5': { type: 'warn_severe', reason: 'Difamaci贸n detectada por IA' }, // Defamation
        'S6': { type: 'warn_middle', reason: 'Consejo especializado inapropiado detectado por IA' }, // Specialized Advice
        'S7': { type: 'warn_severe', reason: 'Violaci贸n de privacidad detectada por IA' }, // Privacy
        'S8': { type: 'warn_middle', reason: 'Violaci贸n de propiedad intelectual detectada por IA' }, // Intellectual Property
        'S9': { type: 'ban', reason: 'Contenido sobre armas peligrosas detectado por IA' }, // Indiscriminate Weapons
        'S10': { type: 'warn_severe', reason: 'Discurso de odio detectado por IA' }, // Hate
        'S11': { type: 'warn_severe', reason: 'Contenido de autolesi贸n detectado por IA' }, // Suicide & Self-Harm
        'S12': { type: 'warn_middle', reason: 'Contenido sexual detectado por IA' }, // Sexual Content
        'S13': { type: 'warn_middle', reason: 'Desinformaci贸n electoral detectada por IA' }, // Elections
    };
    
    return categoryMap[category] || { type: 'warn_mild', reason: 'Contenido inapropiado detectado por IA' };
}

// Apply automated punishment
async function applyAutomatedPunishment(message, punishment) {
    try {
        const toolsModule = await import("../../../tools/punishment.mjs");
        const tools = await toolsModule;
        
        // Apply the punishment
        const punishmentResult = await tools.applyPunishment(
            message.author.id,
            punishment.type,
            punishment.reason + " (Aplicado autom谩ticamente)",
            "SYSTEM_AI"
        );
        
        if (!punishmentResult.success) {
            log(`Failed to apply automated punishment to ${message.author.id}`, 'err');
            return false;
        }
        
        // Send DM to user (required notification about automation)
        await sendAutomatedPunishmentDM(message.author, punishment, message);
        
        // Handle severe punishments (ban)
        if (punishment.type === 'ban') {
            try {
                const member = await message.guild.members.fetch(message.author.id);
                await member.ban({ reason: punishment.reason + " (Aplicado autom谩ticamente)" });
                log(`User ${message.author.id} was automatically banned`, 'warn');
            } catch (error) {
                log(`Failed to ban user ${message.author.id}: ${error.message}`, 'err');
            }
        }
        
        // Check if user has exceeded warning limits
        await checkAndApplyWarningLimits(message, punishment.type, tools);
        
        return true;
    } catch (error) {
        log(`Error applying automated punishment: ${error.message}`, 'err');
        return false;
    }
}

// Send DM notification about automated punishment
async function sendAutomatedPunishmentDM(user, punishment, originalMessage) {
    const severityNames = {
        'warn_mild': 'leve',
        'warn_middle': 'medio', 
        'warn_severe': 'grave',
        'ban': 'ban'
    };
    
    const severityName = severityNames[punishment.type] || punishment.type;
    
    let description;
    if (punishment.type === 'ban') {
        description = `Hola, ${user}. Nos ponemos en contacto con usted mediante el presente comunicado para informarle sobre las medidas que se han tomado debido a su conducta.

**锔 ESTA SANCIN HA SIDO APLICADA AUTOMTICAMENTE POR NUESTRO SISTEMA DE INTELIGENCIA ARTIFICIAL 锔**

Sanci贸n impuesta: **Ban**
Raz贸n: **${punishment.reason}**
Canal: **#${originalMessage.channel.name}**

Esta decisi贸n ha sido tomada por nuestro sistema automatizado de moderaci贸n basado en IA, que analiza el contenido de los mensajes para garantizar un ambiente seguro y respetuoso.

Si considera que esta sanci贸n ha sido aplicada de forma incorrecta, puede apelar contactando con el equipo de moderaci贸n.

Un saludo,
**Sistema Automatizado de Moderaci贸n - Logikk's Discord**`;
    } else {
        description = `Hola, ${user}. Nos ponemos en contacto con usted mediante el presente comunicado para informarle sobre las medidas que se han tomado debido a su conducta.

**锔 ESTA SANCIN HA SIDO APLICADA AUTOMTICAMENTE POR NUESTRO SISTEMA DE INTELIGENCIA ARTIFICIAL 锔**

Sanci贸n impuesta: **Warn ${severityName}**
Raz贸n: **${punishment.reason}**
Canal: **#${originalMessage.channel.name}**

Esta decisi贸n ha sido tomada por nuestro sistema automatizado de moderaci贸n basado en IA, que analiza el contenido de los mensajes para garantizar un ambiente seguro y respetuoso.

Le recomendamos que visite el canal de reglas y eche un vistazo para evitar posibles sanciones en el futuro.
Puede encontrar su historial del servidor en [aqu铆](https://logikk.crujera.net/history).
Si considera que esta sanci贸n ha sido aplicada de forma incorrecta, abra un ticket o contacte con el equipo de moderaci贸n.

Un saludo,
**Sistema Automatizado de Moderaci贸n - Logikk's Discord**`;
    }
    
    const embed = new EmbedBuilder()
        .setColor(punishment.type === 'ban' ? "#000000" : "#ff0000")
        .setTitle(" Mensaje del Sistema Automatizado de Moderaci贸n")
        .setDescription(description)
        .setTimestamp();
    
    try {
        await user.send({ embeds: [embed] });
        log(`Automated punishment DM sent to ${user.username}`, 'info');
    } catch (error) {
        log(`Failed to send automated punishment DM to ${user.username}: ${error.message}`, 'warn');
    }
}

// Check and apply warning limits automatically
async function checkAndApplyWarningLimits(message, punishmentType, tools) {
    try {
        const parseConfigModule = await import("../../../tools/parseConfig.mjs");
        const parseConfig = parseConfigModule.default;
        const appConfig = await parseConfig();
        
        const checkPunishments = await tools.getUserVigentPunishments(message.author.id);
        
        if (!checkPunishments.success) {
            return;
        }
        
        const warnsleves = checkPunishments.punishments.filter(
            (punishment) => punishment.punishment_type === "warn_mild"
        );
        const warnsmedios = checkPunishments.punishments.filter(
            (punishment) => punishment.punishment_type === "warn_middle"
        );
        const warnsgrave = checkPunishments.punishments.filter(
            (punishment) => punishment.punishment_type === "warn_severe"
        );
        
        // Check mild warning limits
        if (warnsleves.length >= appConfig.punishments.limit_warns_mild) {
            await tools.updateExpirationStatusByUserAndType(message.author.id, "warn_mild");
            
            if (appConfig.punishments.reset_cnt_add_nextlvl_warn_on_limit == true) {
                await tools.applyPunishment(
                    message.author.id,
                    "warn_middle",
                    "L铆mite de warns leves superados (autom谩tico)",
                    "SYSTEM_AI"
                );
            }
        }
        
        // Check middle warning limits  
        if (warnsmedios.length >= appConfig.punishments.limit_warns_milddle) {
            await tools.updateExpirationStatusByUserAndType(message.author.id, "warn_middle");
            
            if (appConfig.punishments.reset_cnt_add_nextlvl_warn_on_limit == true) {
                await tools.applyPunishment(
                    message.author.id,
                    "warn_severe", 
                    "L铆mite de warns medios superados (autom谩tico)",
                    "SYSTEM_AI"
                );
            }
        }
        
        // Check severe warning limits
        if (warnsgrave.length >= appConfig.punishments.limit_warns_severe) {
            await tools.updateExpirationStatusByUserAndType(message.author.id, "warn_severe");
            
            try {
                const member = await message.guild.members.fetch(message.author.id);
                await member.ban({ reason: "L铆mite de warns graves superado (autom谩tico)" });
                
                const banEmbed = new EmbedBuilder()
                    .setColor("#000000")
                    .setTitle(" Sistema Automatizado de Moderaci贸n - Ban")
                    .setDescription(
                        `Hola, ${message.author}. Su cuenta ha sido baneada autom谩ticamente del servidor.
                        
**锔 ESTA SANCIN HA SIDO APLICADA AUTOMTICAMENTE POR EXCEDER EL LMITE DE ADVERTENCIAS 锔**

Sanci贸n impuesta: **Ban**
Raz贸n: **L铆mite de warns graves superado**

Esta decisi贸n ha sido tomada autom谩ticamente por nuestro sistema al detectar que ha superado el l铆mite permitido de advertencias graves.

Un saludo,
**Sistema Automatizado de Moderaci贸n - Logikk's Discord**`
                    )
                    .setTimestamp();
                
                try {
                    await message.author.send({ embeds: [banEmbed] });
                } catch (dmError) {
                    log(`Failed to send ban DM to ${message.author.username}: ${dmError.message}`, 'warn');
                }
                
            } catch (error) {
                log(`Failed to ban user for exceeding severe warning limit: ${error.message}`, 'err');
            }
        }
        
    } catch (error) {
        log(`Error checking warning limits: ${error.message}`, 'err');
    }
}

async function canBypassModeration(message) {
    // Admin permission bypass
    if (message.member.permissions.has('Administrator')) return true;

    // Check for bypass role from DB
    const [roles] = await executeQuery(
        'SELECT role_id FROM moderation_bypass WHERE is_active = TRUE'
    );
    
    return message.member.roles.cache.some(role => 
        roles.some(bypass => bypass.role_id === role.id)
    );
}

async function isAIModerationEnabled() {
    const [settings] = await executeQuery(
        'SELECT value FROM settings WHERE name = "ai_moderation_enabled"'
    );
    return settings[0]?.value === '1';
}

module.exports = {
    event: "messageCreate",
    /**
     *
     * @param {ExtendedClient} client
     * @param {Message<true>} message
     * @returns
     */
    run: async (client, message) => {
        if (message.author.bot || message.channel.type === ChannelType.DM) return;

        // Check bypass first
        const bypass = await canBypassModeration(message);
        if (bypass) return;

        const content = message.content.toLowerCase();
        const violation = await checkViolations(content, message);

        if (violation) {
            await message.delete();
            
            switch(violation.severity) {
                case 'mild':
                    // Add mild warning logic
                    break;
                case 'middle':
                    // Add middle warning logic
                    break;
                case 'severe':
                    // Add severe warning logic
                    break;
                case 'ban':
                    // Add ban logic
                    break;
            }
            return;
        }

        // Check if AI moderation is enabled before proceeding
        const aiEnabled = await isAIModerationEnabled();
        if (aiEnabled) {
            // Perform AI moderation check
            const aiPunishment = await performAIModerationCheck(message);
            
            if (aiPunishment) {
                // Delete the message first
                try {
                    await message.delete();
                    log(`Message from ${message.author.username} deleted by AI moderation`, 'warn');
                } catch (deleteError) {
                    log(`Failed to delete message: ${deleteError.message}`, 'err');
                }
                
                // Apply the automated punishment
                const punishmentApplied = await applyAutomatedPunishment(message, aiPunishment);
                
                if (punishmentApplied) {
                    log(`Automated ${aiPunishment.type} applied to ${message.author.username} (${message.author.id}) for: ${aiPunishment.reason}`, 'warn');
                } else {
                    log(`Failed to apply automated punishment to ${message.author.username}`, 'err');
                }
                
                return; // Don't process the message further
            }
        }

        if (!config.handler.commands.prefix) return;

        let prefix = config.handler.prefix;
        prefix = config.handler.prefix;

        if (!message.content.startsWith(prefix)) return;

        const args = message.content.slice(prefix.length).trim().split(/ +/g);
        const commandInput = args.shift().toLowerCase();

        if (!commandInput.length) return;

        let command =
            client.collection.prefixcommands.get(commandInput) ||
            client.collection.prefixcommands.get(
                client.collection.aliases.get(commandInput)
            );

        if (command) {
            try {
                if (
                    command.structure?.permissions &&
                    !message.member.permissions.has(command.structure?.permissions)
                ) {
                    await message.reply({
                        content:
                            config.messageSettings.notHasPermissionMessage !== undefined &&
                                config.messageSettings.notHasPermissionMessage !== null &&
                                config.messageSettings.notHasPermissionMessage !== ""
                                ? config.messageSettings.notHasPermissionMessage
                                : "You do not have the permission to use this command.",
                    });

                    return;
                }

                if (command.structure?.developers) {
                    if (!config.users.developers.includes(message.author.id)) {
                        setTimeout(async () => {
                            await message.reply({
                                content:
                                    config.messageSettings.developerMessage !== undefined &&
                                        config.messageSettings.developerMessage !== null &&
                                        config.messageSettings.developerMessage !== ""
                                        ? config.messageSettings.developerMessage
                                        : "You are not authorized to use this command",
                            });
                        }, 5 * 1000);
                    }

                    return;
                }

                if (command.structure?.nsfw && !message.channel.nsfw) {
                    await message.reply({
                        content:
                            config.messageSettings.nsfwMessage !== undefined &&
                                config.messageSettings.nsfwMessage !== null &&
                                config.messageSettings.nsfwMessage !== ""
                                ? config.messageSettings.nsfwMessage
                                : "The current channel is not a NSFW channel.",
                    });

                    return;
                }

                if (command.structure?.cooldown) {
                    const cooldownFunction = () => {
                        let data = cooldown.get(message.author.id);

                        data.push(commandInput);

                        cooldown.set(message.author.id, data);

                        setTimeout(() => {
                            let data = cooldown.get(message.author.id);

                            data = data.filter((v) => v !== commandInput);

                            if (data.length <= 0) {
                                cooldown.delete(message.author.id);
                            } else {
                                cooldown.set(message.author.id, data);
                            }
                        }, command.structure?.cooldown);
                    };

                    if (cooldown.has(message.author.id)) {
                        let data = cooldown.get(message.author.id);

                        if (data.some((v) => v === commandInput)) {
                            await message.reply({
                                content:
                                    (config.messageSettings.cooldownMessage !== undefined &&
                                        config.messageSettings.cooldownMessage !== null &&
                                        config.messageSettings.cooldownMessage !== ""
                                        ? config.messageSettings.cooldownMessage
                                        : "Slow down buddy! You're too fast to use this command ({cooldown}s).").replace(/{cooldown}/g, command.structure.cooldown / 1000),
                            });

                            return;
                        } else {
                            cooldownFunction();
                        }
                    } else {
                        cooldown.set(message.author.id, [commandInput]);

                        cooldownFunction();
                    }
                }

                command.run(client, message, args);
            } catch (error) {
                log(error, "err");
            }
        }
    },
};
